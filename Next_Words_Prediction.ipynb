{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPwpGgcGZ1dtuE9HsURhXHQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anshad-Aziz/Machine_Learning/blob/main/Next_Words_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9TejSbUNMshZ"
      },
      "outputs": [],
      "source": [
        "import tensorflow\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import Embedding,LSTM,Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import pickle\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file=open('/content/Sherlock Holmes.txt','r',encoding=\"utf8\")"
      ],
      "metadata": {
        "id": "G_A-MUjdMzsL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines=[]\n",
        "for i in file:\n",
        "  lines.append(i)"
      ],
      "metadata": {
        "id": "NDkA4SDoM9k5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=\"\"\n",
        "for i in lines:\n",
        "  data=' '.join(lines)"
      ],
      "metadata": {
        "id": "eMlb7h5KPkZC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=data.replace('\\n','').replace('\\r','').replace('\\ufeff','').replace('‚Äù','')"
      ],
      "metadata": {
        "id": "yFOKTEeiPsbu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=data.split()\n",
        "data=' '.join(data)"
      ],
      "metadata": {
        "id": "6sQIhyzSQDZ2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[:1000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "J9IKMBaFQUF-",
        "outputId": "e6a53a16-8077-492d-c145-8c31d739c584"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"THE ADVENTURES OF SHERLOCK HOLMES Arthur Conan Doyle Table of contents A Scandal in Bohemia The Red-Headed League A Case of Identity The Boscombe Valley Mystery The Five Orange Pips The Man with the Twisted Lip The Adventure of the Blue Carbuncle The Adventure of the Speckled Band The Adventure of the Engineer's Thumb The Adventure of the Noble Bachelor The Adventure of the Beryl Coronet The Adventure of the Copper Beeches A SCANDAL IN BOHEMIA Table of contents Chapter 1 Chapter 2 Chapter 3 CHAPTER I To Sherlock Holmes she is always the woman. I have seldom heard him mention her under any other name. In his eyes she eclipses and predominates the whole of her sex. It was not that he felt any emotion akin to love for Irene Adler. All emotions, and that one particularly, were abhorrent to his cold, precise but admirably balanced mind. He was, I take it, the most perfect reasoning and observing machine that the world has seen, but as a lover he would have placed himself in a false position\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=Tokenizer()\n",
        "tokenizer.fit_on_texts([data])"
      ],
      "metadata": {
        "id": "OAKAnrgBQWTI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(tokenizer,open('token.pkl','wb'))"
      ],
      "metadata": {
        "id": "oVyP5tk_Qh19"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_data=tokenizer.texts_to_sequences([data])[0]"
      ],
      "metadata": {
        "id": "jputcWdAQqn-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_data[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtHWfhjnQzqs",
        "outputId": "eb44a252-d2b3-4419-8fda-c9937b11a910"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 1561, 5, 129, 34, 647, 4498, 4499, 226, 5]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(sequence_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffhiDjDhRE8V",
        "outputId": "ecd85fd5-7475-4370-849c-b1eb6e3fca2d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "105879"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size=len(tokenizer.word_index)+1"
      ],
      "metadata": {
        "id": "1wlcILGRRIEQ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyQ5-lkrRPXM",
        "outputId": "2e6c61c6-4fb6-4f24-ebef-cfe82666c62b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8200"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequence=[]\n",
        "for i in range(3,len(sequence_data)):\n",
        "  words=sequence_data[i-3:i+1]\n",
        "  sequence.append(words)"
      ],
      "metadata": {
        "id": "0xjTPPrFRRiX"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(sequence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSr5_nD-RmX-",
        "outputId": "f52a0a80-f66c-41ce-9371-46236070938a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "105876"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequence=np.array(sequence)"
      ],
      "metadata": {
        "id": "RjoTO6bxRpHy"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "sequence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTWuYZbHRt29",
        "outputId": "f080a429-7f4b-48fc-a0d6-09dcae682f7d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   1, 1561,    5,  129],\n",
              "       [1561,    5,  129,   34],\n",
              "       [   5,  129,   34,  647],\n",
              "       ...,\n",
              "       [  28,    1, 8198, 8199],\n",
              "       [   1, 8198, 8199, 3187],\n",
              "       [8198, 8199, 3187, 3186]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=[]\n",
        "y=[]\n",
        "for i in sequence:\n",
        "  x.append(i[0:3])\n",
        "  y.append(i[3])"
      ],
      "metadata": {
        "id": "HeZ6HLYIRvY5"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=np.array(x)\n",
        "y=np.array(y)"
      ],
      "metadata": {
        "id": "z55wvYC6R6JB"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "y=to_categorical(y,num_classes=vocab_size)"
      ],
      "metadata": {
        "id": "4qo8VojjSAAw"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0vYWB3MSGYP",
        "outputId": "1312fcf0-be2b-4c6c-b578-f9011f7c853c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(Embedding(vocab_size,10,input_length=3))\n",
        "model.add(LSTM(1000,return_sequences=True))\n",
        "model.add(LSTM(1000))\n",
        "model.add(Dense(1000,activation='relu'))\n",
        "model.add(Dense(vocab_size,activation=\"softmax\"))"
      ],
      "metadata": {
        "id": "kxKTuKVESIGj"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlpL8q48SwCy",
        "outputId": "8b17acc9-faa5-452e-8412-642f7465a0a9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 3, 10)             82000     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 3, 1000)           4044000   \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 1000)              8004000   \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1000)              1001000   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 8200)              8208200   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21339200 (81.40 MB)\n",
            "Trainable params: 21339200 (81.40 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "checkpoint=ModelCheckpoint(\"next_words.h5\",monitor=\"loss\",verbose=1,save_best_only=True)\n",
        "model.compile(loss=\"categorical_crossentropy\",optimizer=Adam(learning_rate=0.001))\n",
        "model.fit(x,y,epochs=2,batch_size=64,callbacks=[checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbPK_J_cSy97",
        "outputId": "17d6bf41-1903-457e-eb9f-04e0c03a6650"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "1655/1655 [==============================] - ETA: 0s - loss: 6.3441\n",
            "Epoch 1: loss improved from inf to 6.34412, saving model to next_words.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1655/1655 [==============================] - 45s 22ms/step - loss: 6.3441\n",
            "Epoch 2/2\n",
            "1655/1655 [==============================] - ETA: 0s - loss: 5.7617\n",
            "Epoch 2: loss improved from 6.34412 to 5.76174, saving model to next_words.h5\n",
            "1655/1655 [==============================] - 30s 18ms/step - loss: 5.7617\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c8482564d60>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VutBDm1vUP9x"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YvhLZBj8V7Ps"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}